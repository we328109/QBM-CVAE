{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结：Quantum Variational Autoencoder（QVAE）原理与代码实现\n",
    "\n",
    "---\n",
    "\n",
    "## 一、QVAE 原理概括\n",
    "\n",
    "QVAE（Quantum Variational Autoencoder）是一种将 **量子生成模型** 引入 **变分自编码器(VAE)** 潜空间的生成模型。其核心思想是：\n",
    "\n",
    "> **用量子玻尔兹曼机（QBM）替代传统VAE中的先验分布，从而构建一个具有量子生成能力的潜变量模型。**\n",
    "\n",
    "### 模型结构\n",
    "\n",
    "QVAE 包括以下关键组件：\n",
    "\n",
    "1. **编码器（Encoder）**：  \n",
    "   将输入数据 x 映射为潜变量的近似后验分布  \n",
    "   $q_\\phi(z|x)$，通常由神经网络参数化。\n",
    "\n",
    "2. **先验分布（Prior）**：  \n",
    "   使用 **量子玻尔兹曼机(QBM)** 建模潜变量 z 的先验分布。哈密顿量为：  \n",
    "   $$\n",
    "   \\mathcal{H}_\\theta = \\sum_l \\Gamma_l \\sigma_l^x + \\sum_l h_l \\sigma_l^z + \\sum_{l<m} W_{lm} \\sigma_l^z \\sigma_m^z\n",
    "   $$\n",
    "\n",
    "3. **解码器（Decoder）**：  \n",
    "   将潜变量 z（或其连续松弛变量 $\\zeta$）映射回数据空间，并使用解码器重建原始数据：  \n",
    "   $$\n",
    "   p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta}) \\approx \\text{Bernoulli}(f_\\theta(\\boldsymbol{\\zeta}))\n",
    "   $$\n",
    "\n",
    "### 训练目标：Q-ELBO\n",
    "\n",
    "QVAE 使用一个 **量子下界(Q-ELBO)** 来近似最大化对数似然：\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{Q-ELBO}} = \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} [\\log p_\\theta(\\mathbf{x} | \\boldsymbol{\\zeta})] - \\tilde{H}(q_\\phi(\\mathbf{z}|\\mathbf{x}) \\| p_\\theta(\\mathbf{z}))\n",
    "$$\n",
    "\n",
    "### QBM采样与训练\n",
    "\n",
    "- **正相（positive phase）**：从编码器采样  $z \\sim q_\\phi(z|x)$\n",
    "- **负相（negative phase）**：从 QBM 中采样 $z \\sim p_\\theta(z)$，使用 **蒙特卡洛方法** 或 **量子退火器**\n",
    "把能量作为目标函数，objective的梯度即为基于正相和负相采样计算的梯度\n",
    "\n",
    "## 二、代码架构概述\n",
    "\n",
    "```bash\n",
    "\n",
    "QVAE 完整训练流程\n",
    "│\n",
    "├── 1. 数据准备 (setup_data_loaders)\n",
    "│   ├── MNIST数据集加载\n",
    "│   ├── 图像展平预处理 (784维向量)\n",
    "│   └── 训练/测试集划分\n",
    "│\n",
    "├── 2. 模型构建 (QVAE)\n",
    "│   ├── 编码器 (Encoder)\n",
    "│   ├── 解码器 (Decoder) \n",
    "│   └── RBM先验 (RestrictedBoltzmannMachine)\n",
    "│\n",
    "├── 3. 训练监控 (train_qvae_with_tsne)\n",
    "│   ├── 前向传播 (neg_elbo计算)\n",
    "│   ├── 反向传播 (梯度更新)\n",
    "│   ├── t-SNE可视化跟踪\n",
    "│   └── 训练动态动画生成\n",
    "│\n",
    "├── 4. 图像生成\n",
    "│   ├── 重构原始图像\n",
    "│   └── 新样本生成\n",
    "│\n",
    "└── 5. 质量评估\n",
    "    └── FID分数计算\n",
    "```\n",
    "\n",
    "\n",
    "## 三、代码内容概括\n",
    "\n",
    "该例子实现了一个 **基于 MNIST 的 QVAE 训练流程**，包括以下模块：\n",
    "\n",
    "\n",
    "### 模型构建\n",
    "\n",
    "- 使用自定义 `QVAE` 类：\n",
    "  - 编码器/解码器为全连接网络；\n",
    "  - 使用 `mean_x` 作为模型偏移量；\n",
    "  - 包含玻尔兹曼机作为先验分布\n",
    "\n",
    "### 训练过程\n",
    "\n",
    "- 优化器：Adam，学习率 1e-3；\n",
    "- 损失函数：`loss = neg_elbo + wd_loss`，即包含ELBO下界和weight decay\n",
    "- 每个 epoch 保存模型权重；\n",
    "- 记录并保存以下历史数据：\n",
    "  - `loss_history`\n",
    "  - `elbo_history`\n",
    "  - `kl_history`\n",
    "  - `cost_history`\n",
    "\n",
    "\n",
    "### 图像生成流程\n",
    "\n",
    "1. 从 RBM 中采样潜变量 `z`；\n",
    "2. 引入平滑分布 `Exponential(beta)` 采样 `zeta`；\n",
    "3. 使用解码器生成图像：\n",
    "   $$\n",
    "   \\text{generated\\_x} = \\sigma(\\text{decoder}(zeta) + \\text{train\\_bias})\n",
    "   $$\n",
    "\n",
    "### FID 评估\n",
    "\n",
    "- 使用 `torchmetrics.image.fid.FrechetInceptionDistance`；\n",
    "- 提供函数：\n",
    "  - `get_real_images()`：从验证集获取真实图像；\n",
    "  - `generate_images_qvae()`：使用 QVAE 生成图像；\n",
    "  - `compute_fid_in_batches()`：计算 FID 分数（适配 MNIST）；\n",
    "- 最终输出 QVAE 在 MNIST 上的 FID 分数。\n",
    "\n",
    "\n",
    "\n",
    "## 四、总结\n",
    "\n",
    "> QVAE = VAE 的编码器/解码器 + QBM 的量子先验，通过最大化量子下界（Q-ELBO）实现端到端训练；  \n",
    "> 代码包含MNIST 数据集，QVAE 模型，训练循环，图像可视化和FID 评估，完整实现了量子自编码器模型的实验流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kaiwu.classical import SimulatedAnnealingOptimizer\n",
    "from utils import get_real_images, generate_images_qvae, compute_fid_in_batches\n",
    "from visualizers import t_SNE, plot_flattened_images_grid\n",
    "\n",
    "model_name = \"QVAE_annealing_tanh\"\n",
    "save_path = f\"./models/{model_name}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 添加kaiwu的license信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据转换操作\n",
    "def flatten_tensor(x):\n",
    "    return x.view(-1)\n",
    "\n",
    "\n",
    "def setup_data_loaders(root, download=True, batch_size=256, use_cuda=False):\n",
    "    \"\"\"\n",
    "    设置MNIST数据集的数据加载器\n",
    "\n",
    "    Args:\n",
    "        root (str): 数据存储根目录\n",
    "        download (bool): 如果数据不存在是否下载，默认为True\n",
    "        batch_size (int): 每个批次的样本数量，默认为128\n",
    "        use_cuda (bool): 是否使用GPU，决定是否启用pin_memory优化\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader) 训练和测试数据加载器\n",
    "    \"\"\"\n",
    "    # 数据预处理\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),  # 转换为Tensor\n",
    "            transforms.Lambda(flatten_tensor),  # 展平：将28x28图像展平成784维向量\n",
    "            # 等效于：x.reshape(-1) 或 x.flatten()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 加载训练集\n",
    "    train_set = datasets.MNIST(\n",
    "        root=root,  # 数据存储路径\n",
    "        train=True,  # 加载训练集（共60000个样本）\n",
    "        transform=transform,  # 应用定义的数据变换\n",
    "        download=download,  # 如果数据不存在则自动下载\n",
    "    )\n",
    "\n",
    "    # 加载测试集\n",
    "    test_set = datasets.MNIST(\n",
    "        root=root,  # 数据存储路径\n",
    "        train=False,  # 加载测试集（共10000个样本）\n",
    "        transform=transform,  # 应用相同的数据变换\n",
    "    )\n",
    "\n",
    "    # 数据加载器配置参数\n",
    "    # 根据是否使用GPU选择不同的优化参数\n",
    "    # 将num_workers设为0避免多进程问题\n",
    "    kwargs = {\"num_workers\": 0, \"pin_memory\": True} if use_cuda else {\"num_workers\": 0}\n",
    "\n",
    "    # 创建训练数据加载器\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_set,  # 训练数据集\n",
    "        batch_size=batch_size,  # 每个批次的样本数\n",
    "        shuffle=True,  # 每个epoch打乱数据顺序，防止模型记忆顺序\n",
    "        **kwargs,  # 解包上述配置参数\n",
    "    )\n",
    "\n",
    "    # 创建测试数据加载器\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_set,  # 测试数据集\n",
    "        batch_size=batch_size,  # 批次大小（通常与训练集相同）\n",
    "        shuffle=False,  # 测试集不需要打乱，保证可重复性\n",
    "        **kwargs,  # 解包配置参数\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练QVAE (t-SNE可视化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_qvae import train_qvae_with_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    smoke_test = True\n",
    "\n",
    "    # 初始化Q-VAE参数\n",
    "    input_dim = 784\n",
    "    hidden_dim = 512\n",
    "    latent_dim = 256\n",
    "    num_var1 = 128\n",
    "    num_var2 = 128\n",
    "    dist_beta = 10\n",
    "    kl_beta = 0.000001\n",
    "    vae_batch_size = 256\n",
    "    vae_epochs = 2 if smoke_test else 20\n",
    "    vae_lr = 1e-3\n",
    "\n",
    "    # 初始化MLP参数\n",
    "    cls_epochs = 100\n",
    "    cls_lr = 1e-3\n",
    "    cls_batch_size = 64\n",
    "\n",
    "    # 数据加载\n",
    "    train_loader, test_loader = setup_data_loaders(\n",
    "        root=\"../../data\",\n",
    "        download=True,\n",
    "        batch_size=vae_batch_size,\n",
    "        use_cuda=False,  # 如果系统有GPU且已安装CUDA\n",
    "    )\n",
    "\n",
    "    # 1. 训练Q-VAE（实时t-SNE可视化）\n",
    "    print(\"=== Training Q-VAE with t-SNE visualization ===\")\n",
    "    qvae = train_qvae_with_tsne(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        latent_dim=latent_dim,\n",
    "        num_var1=num_var1,\n",
    "        num_var2=num_var2,\n",
    "        dist_beta=dist_beta,\n",
    "        batch_size=vae_batch_size,\n",
    "        epochs=vae_epochs,\n",
    "        lr=vae_lr,\n",
    "        kl_beta=kl_beta,\n",
    "        device=device,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        tsne_interval=(\n",
    "            1 if smoke_test else 2\n",
    "        ),  # smoke_test时更频繁，正常训练每2个epoch一次\n",
    "        animation_save_path=os.path.join(save_path, \"qva_training_evolution.gif\"),\n",
    "    )\n",
    "\n",
    "    # 2. 生成最终的t-SNE图像\n",
    "    print(\"\\nGenerating final high-quality t-SNE visualization...\")\n",
    "    final_tsne_path = os.path.join(\n",
    "        save_path, f\"QVAE_final_t-SNE_epochs_{vae_epochs}.png\"\n",
    "    )\n",
    "    df_tsne_final, final_save_path, _ = t_SNE(\n",
    "        test_loader, qvae, epochs=vae_epochs, save_path=final_tsne_path, show=True\n",
    "    )\n",
    "\n",
    "    # 3. 评估: 重构可视化\n",
    "    print(\"\\n=== Image Generation and Reconstruction Visualization ===\")\n",
    "\n",
    "    # 从训练数据加载器中取出一个批次的特征（features），忽略标签\n",
    "    features, _ = next(iter(train_loader))\n",
    "\n",
    "    # 将原始输入特征（展平的图像）以8x8网格形式可视化并保存为original.png\n",
    "    original_save_path = os.path.join(save_path, \"original.png\")\n",
    "    print(f\"Visualizing original images, saving to: {original_save_path}\")\n",
    "    plot_flattened_images_grid(features, grid_size=8, save_path=original_save_path)\n",
    "\n",
    "    # 将特征数据移动到指定设备（CPU或GPU）\n",
    "    features = features.to(device)\n",
    "    qvae.eval()  # 设置模型为评估模式（关闭dropout、BN等训练特性）\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算以节省内存\n",
    "        # 前向传播：用QVAE模型计算重构结果和各项损失\n",
    "        output, recon_x, neg_elbo, wd_loss, kl, cost, q, zeta = qvae.neg_elbo(\n",
    "            features, kl_beta\n",
    "        )\n",
    "\n",
    "        # 可视化重构图像,并保存为recon_x.png\n",
    "        recon_save_path = os.path.join(save_path, \"recon_x.png\")\n",
    "        print(f\"Visualizing reconstructed images, saving to: {recon_save_path}\")\n",
    "        plot_flattened_images_grid(output.cpu(), grid_size=8, save_path=recon_save_path)\n",
    "\n",
    "    # 4. 评估: 生成新图像\n",
    "    from torch.distributions import Exponential\n",
    "\n",
    "    print(\"\\n=== Generating New Images ===\")\n",
    "\n",
    "    # 初始化采样器\n",
    "    sampler = SimulatedAnnealingOptimizer(size_limit=100, alpha=0.99)\n",
    "\n",
    "    # 从RBM采样\n",
    "    z = qvae.bm.sample(sampler)\n",
    "    shape = z.shape\n",
    "\n",
    "    # 创建平滑分布并采样\n",
    "    smoothing_dist = Exponential(dist_beta)\n",
    "    zeta = smoothing_dist.sample(shape)  # 从平滑分布采样\n",
    "    zeta = zeta.to(z.device)\n",
    "\n",
    "    # 应用z的条件变换\n",
    "    zeta = torch.where(z == 0.0, zeta, 1 - zeta)  # 引入z\n",
    "\n",
    "    # 通过解码器生成图像\n",
    "    with torch.no_grad():\n",
    "        generated_x = qvae.decoder(zeta)\n",
    "        generated_x = generated_x + qvae.train_bias  # 添加训练偏置\n",
    "        generated_x = torch.sigmoid(generated_x)  # 应用sigmoid激活\n",
    "\n",
    "    # 可视化生成图像,并保存为generated_x.png\n",
    "    generated_save_path = os.path.join(save_path, \"generated_x.png\")\n",
    "    print(f\"Visualizing generated images, saving to: {generated_save_path}\")\n",
    "    plot_flattened_images_grid(\n",
    "        generated_x.cpu(), grid_size=8, save_path=generated_save_path\n",
    "    )\n",
    "\n",
    "    # 5. FID评估\n",
    "    print(\"\\n=== FID Evaluation ===\")\n",
    "\n",
    "    # 获取真实图像和生成图像\n",
    "    print(\"Collecting real images...\")\n",
    "    real_imgs = get_real_images(test_loader, n_images=10000)\n",
    "    print(f\"Real images shape: {real_imgs.shape}\")\n",
    "\n",
    "    print(\"\\nGenerating QVAE images...\")\n",
    "    fake_imgs_original_vae = generate_images_qvae(\n",
    "        qvae, n_images=10000, dist_beta=dist_beta, latent_dim=latent_dim\n",
    "    )\n",
    "    print(f\"Generated images shape: {fake_imgs_original_vae.shape}\")\n",
    "\n",
    "    # 计算 FID（更节省内存）\n",
    "    print(\"\\nComputing FID score for QVAE...\")\n",
    "    fid_original = compute_fid_in_batches(\n",
    "        fake_imgs_original_vae, real_imgs, device=device\n",
    "    )\n",
    "    print(f\"QVAE FID Score: {fid_original:.2f}\")\n",
    "\n",
    "    # 保存FID结果\n",
    "    fid_result_path = os.path.join(save_path, \"fid_results.txt\")\n",
    "    with open(fid_result_path, \"w\") as f:\n",
    "        f.write(f\"FID分数: {fid_original:.4f}\\n\")\n",
    "        f.write(f\"训练轮次: {vae_epochs}\\n\")\n",
    "        f.write(f\"潜在维度: {latent_dim}\\n\")\n",
    "        f.write(f\"评估时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    print(f\"\\n=== 运行完成 ===\")\n",
    "    print(f\"所有结果已保存到: {save_path}\")\n",
    "    print(f\"原始图像: {original_save_path}\")\n",
    "    print(f\"重构图像: {recon_save_path}\")\n",
    "    print(f\"生成图像: {generated_save_path}\")\n",
    "    print(f\"最终t-SNE: {final_tsne_path}\")\n",
    "    print(f\"训练动画: {os.path.join(save_path, 'qva_training_evolution.gif')}\")\n",
    "    print(f\"FID结果: {fid_result_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
